var documenterSearchIndex = {"docs":
[{"location":"guide/utils/#Utilities","page":"Utilities","title":"Utilities","text":"","category":"section"},{"location":"guide/utils/#SFST-utilities","page":"Utilities","title":"SFST utilities","text":"","category":"section"},{"location":"guide/utils/","page":"Utilities","title":"Utilities","text":"Kanones and Tabulae are Julia packages for building ancient Greek and Latin morphological parsers, respectively.  Both Kanones and Tabulae do their parsing behind the scenes using finite state transducers built with the Stuttgart Finite State Transducer toolkit.  To facilitate this work, CitableParserBuilder includes utilities for transcoding string values to and from URN values and expressions in SFST-PL, the programmning language of the Stuttgart Finite State Transducer tooolkit.","category":"page"},{"location":"guide/parser/#Users'-guide:-using-a-CitableParser","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"","category":"section"},{"location":"guide/parser/","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"Any implementation of a CitableParser works in basically the same way.  The parsing functions all have a common pair of signatures:","category":"page"},{"location":"guide/parser/","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"function(textcontent, parser)\nfunction(content, parser, parserdata)","category":"page"},{"location":"guide/parser/","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"The sample parser we will use requires the third, data parameter: check the documentation for your specific parser to see how it works.","category":"page"},{"location":"guide/parser/","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"Here we instantiate the sample parser, and verify that it is indeed a subtype of CitableParser.","category":"page"},{"location":"guide/parser/","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"using CitableParserBuilder\nparser = CitableParserBuilder.gettysburgParser()\ntypeof(parser) |> supertype\n\n# output\n\n[ Info: Loading dictionary over the internet...\n[ Info: Done loading.\nCitableParser","category":"page"},{"location":"guide/parser/#Parsing-string-values","page":"Users' guide: using a CitableParser","title":"Parsing string values","text":"","category":"section"},{"location":"guide/parser/","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"When we parse a string token, the result is a Vector of Analysis objects. Our parser produces only one analysis for score.","category":"page"},{"location":"guide/parser/","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"scoreparses = parsetoken(\"score\", parser; data = parser.data)\nlength(scoreparses)\n\n# output\n\n1","category":"page"},{"location":"guide/parser/","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"typeof(scoreparses[1])\n\n# output\n\nAnalysis","category":"page"},{"location":"guide/parser/","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"The analysis object associates with the token a URN value, in abbreviated format, for each of the four properties of an analysis.","category":"page"},{"location":"guide/parser/","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"scoreparses[1].token\n\n# output\n\n\"score\"","category":"page"},{"location":"guide/parser/","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"scoreparses[1].form\n\n# output\n\ngburgform.NN","category":"page"},{"location":"guide/parser/","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"NN is the Penn Tree Bank code for Noun, singular or mass.","category":"page"},{"location":"guide/parser/","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"We can also parse a list of words. Here, parsing four words produces a Vector containing four Vectors of Analysis objects.","category":"page"},{"location":"guide/parser/","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"wordsparsed = parsewordlist(split(\"Four score and seven\"), parser; data =  parser.data)\nlength(wordsparsed)\n\n# output\n\n4","category":"page"},{"location":"guide/parser/","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"tip: Tip\nYou can use an OrthographicSystem to create generate a list of unique lexical tokens for an entire citable corpus. See the documentation for the Orthography module.","category":"page"},{"location":"guide/parser/#Parsing-citable-text-content","page":"Users' guide: using a CitableParser","title":"Parsing citable text content","text":"","category":"section"},{"location":"guide/parser/","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"You can also parse citable text structures: passages, documents and corpora.  Here we illustrate parsing a citable passage.","category":"page"},{"location":"guide/parser/","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"using CitableText, CitableCorpus\nurn = CtsUrn(\"urn:cts:demo:gburg.hays.v2:1.2\")\npsg = CitablePassage(urn, \"score\")\npsg_analysis = parsepassage(psg, parser; data = parser.data)\ntypeof(psg_analysis)\n\n# output\n\nAnalyzedToken","category":"page"},{"location":"guide/parser/","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"The result is a new kind of object, the AnalyzedToken, which associates a Vector of Analysis objects with a citable passage.","category":"page"},{"location":"guide/parser/","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"psg_analysis.passage\n\n# output\n\n<urn:cts:demo:gburg.hays.v2:1.2> score","category":"page"},{"location":"guide/parser/","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"psg_analysis.analyses == scoreparses\n\n# output\n\ntrue","category":"page"},{"location":"guide/parser/#Exporting-to-CEX-format","page":"Users' guide: using a CitableParser","title":"Exporting to CEX format","text":"","category":"section"},{"location":"guide/parser/","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"When we export analyses to CEX format, we want to use full CITE2 URNs, rather than the abbreviated URNs of the Analysis structure.  You need a dictionary mapping collection names to full CITE2 URN values for the collection.","category":"page"},{"location":"guide/parser/","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"registry = Dict(\n        \"gburglex\" => \"urn:cite2:citedemo:gburglex.v1:\",\n        \"gburgform\" => \"urn:cite2:citedemo:gburgform.v1:\",\n        \"gburgrule\" => \"urn:cite2:citedemo:gburgrule.v1:\",\n        \"gburgstem\" => \"urn:cite2:citedemo:gburgstem.v1:\"\n    )\nlength(registry)\n\n# output\n\n4","category":"page"},{"location":"guide/parser/","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"Include the dictionary along with your list of analyses as parameters to the cex function to expand abbreviated URNs to their full form.  You can use normal Julia IO to write the results to a file, for example.","category":"page"},{"location":"guide/parser/","page":"Users' guide: using a CitableParser","title":"Users' guide: using a CitableParser","text":"cex_output = cex(psg_analysis, registry = registry)\nopen(\"outfile.cex\", \"w\") do io\n    write(io, cex_output)\nend\n\n# output\n\n186","category":"page"},{"location":"guide/parsevectors/#Working-with-vectors-of-AnalyzedTokens","page":"Working with vectors of AnalyzedTokens","title":"Working with vectors of AnalyzedTokens","text":"","category":"section"},{"location":"guide/parsevectors/","page":"Working with vectors of AnalyzedTokens","title":"Working with vectors of AnalyzedTokens","text":"Same set up as before: read corpus, tokenize, parse.","category":"page"},{"location":"guide/parsevectors/","page":"Working with vectors of AnalyzedTokens","title":"Working with vectors of AnalyzedTokens","text":"using CitableCorpus\nrepo = dirname(pwd()) |> dirname |> dirname # hide\nf = joinpath(repo,\"test\",\"data\",\"gettysburgcorpus.cex\") \ncorpus = read(f) |> corpus_fromcex\n\nusing Orthography\ntc = tokenizedcorpus(corpus, simpleAscii())\n\ndictcsv = joinpath(repo, \"test\", \"data\", \"posdict.csv\") \nusing CSV\nmorphdict = CSV.File(dictcsv) |> Dict\nusing CitableParserBuilder\nparser = CitableParserBuilder.gettysburgParser(dict = morphdict)","category":"page"},{"location":"guide/parsevectors/","page":"Working with vectors of AnalyzedTokens","title":"Working with vectors of AnalyzedTokens","text":"parsed =  parsecorpus(tc, parser; data = parser.data)\nlength(parsed)","category":"page"},{"location":"guide/parsevectors/#Lexemes","page":"Working with vectors of AnalyzedTokens","title":"Lexemes","text":"","category":"section"},{"location":"guide/parsevectors/","page":"Working with vectors of AnalyzedTokens","title":"Working with vectors of AnalyzedTokens","text":"Get a list of unique lexeme identifiers for all parsed tokens.","category":"page"},{"location":"guide/parsevectors/","page":"Working with vectors of AnalyzedTokens","title":"Working with vectors of AnalyzedTokens","text":"lexemelist = lexemes(parsed)\nlength(lexemelist)","category":"page"},{"location":"guide/parsevectors/","page":"Working with vectors of AnalyzedTokens","title":"Working with vectors of AnalyzedTokens","text":"For a given lexeme, find all surface forms appearing in the corpus.  The lexeme \"gburglex.and\" appears in only one form, and.","category":"page"},{"location":"guide/parsevectors/","page":"Working with vectors of AnalyzedTokens","title":"Working with vectors of AnalyzedTokens","text":"stringsforlexeme(parsed, \"gburglex.and\" )","category":"page"},{"location":"guide/parsevectors/","page":"Working with vectors of AnalyzedTokens","title":"Working with vectors of AnalyzedTokens","text":"Get a dictionary keyed by lexeme that can be used to find all forms, and all passages for a given lexeme.  It will have the same length as the list of lexemes, which are its keys.","category":"page"},{"location":"guide/parsevectors/","page":"Working with vectors of AnalyzedTokens","title":"Working with vectors of AnalyzedTokens","text":"ortho = simpleAscii() # hide\ntokenindex = corpusindex(corpus, ortho)\nlexdict = lexemedictionary(parsed, tokenindex)\nlength(lexdict)","category":"page"},{"location":"guide/parsevectors/","page":"Working with vectors of AnalyzedTokens","title":"Working with vectors of AnalyzedTokens","text":"Each entry in the dictionary is a further dictionary mapping surface forms to passages.","category":"page"},{"location":"guide/parsevectors/","page":"Working with vectors of AnalyzedTokens","title":"Working with vectors of AnalyzedTokens","text":"lexdict[\"gburglex.and\"]","category":"page"},{"location":"man/#API-documentation","page":"API documentation","title":"API documentation","text":"","category":"section"},{"location":"man/#Structures","page":"API documentation","title":"Structures","text":"","category":"section"},{"location":"man/","page":"API documentation","title":"API documentation","text":"AbbreviatedUrn\nStem\nRule\nAnalysis\nStemUrn\nRuleUrn\nLexemeUrn\nFormUrn\nAnalyzedToken","category":"page"},{"location":"man/#CitableParserBuilder.AbbreviatedUrn","page":"API documentation","title":"CitableParserBuilder.AbbreviatedUrn","text":"Short form of a Cite2Urn containing only collection and object ID.\n\n\n\n\n\n","category":"type"},{"location":"man/#CitableParserBuilder.Stem","page":"API documentation","title":"CitableParserBuilder.Stem","text":"Supertype of all concrete Stem structures.\n\n\n\n\n\n","category":"type"},{"location":"man/#CitableParserBuilder.Rule","page":"API documentation","title":"CitableParserBuilder.Rule","text":"Supertype of all concrete Rule structures.\n\n\n\n\n\n","category":"type"},{"location":"man/#CitableParserBuilder.Analysis","page":"API documentation","title":"CitableParserBuilder.Analysis","text":"Citable analysis of a string value.\n\nAn Analysis has five members: a token string value, and four abbreviated URNs, one each for the lexeme, form, rule and stem.\n\n\n\n\n\n","category":"type"},{"location":"man/#CitableParserBuilder.StemUrn","page":"API documentation","title":"CitableParserBuilder.StemUrn","text":"Abbreviated URN for a morphological stem.\n\n\n\n\n\n","category":"type"},{"location":"man/#CitableParserBuilder.RuleUrn","page":"API documentation","title":"CitableParserBuilder.RuleUrn","text":"Abbreviated URN for rule.\n\n\n\n\n\n","category":"type"},{"location":"man/#CitableParserBuilder.LexemeUrn","page":"API documentation","title":"CitableParserBuilder.LexemeUrn","text":"Abbreviated URN for a lexeme.\n\n\n\n\n\n","category":"type"},{"location":"man/#CitableParserBuilder.FormUrn","page":"API documentation","title":"CitableParserBuilder.FormUrn","text":"Abbreviated URN for a morphological form.\n\n\n\n\n\n","category":"type"},{"location":"man/#CitableParserBuilder.AnalyzedToken","page":"API documentation","title":"CitableParserBuilder.AnalyzedToken","text":"Morphological analyses for a token identified by CTS URN.\n\n\n\n\n\n","category":"type"},{"location":"man/#Parsing","page":"API documentation","title":"Parsing","text":"","category":"section"},{"location":"man/","page":"API documentation","title":"API documentation","text":"parsetoken\nparsewordlist\nparselistfromfile\nparselistfromurl\nparsepassage\nparsecorpus","category":"page"},{"location":"man/#CitableParserBuilder.parsetoken","page":"API documentation","title":"CitableParserBuilder.parsetoken","text":"Delegate to specific functions based on type's citable trait value.\n\nparsetoken(s, x; data)\n\n\n\n\n\n\nIt is an error to invoke the parsetoken using types that are not a parser.\n\nparsetoken(, s, x; data)\n\n\n\n\n\n\nCitable parsers must implement parsetoken.\n\nparsetoken(, s, x; data)\n\n\n\n\n\n\nParse String s by looking it up in a given dictionary.\n\n\n\n\n\n","category":"function"},{"location":"man/#CitableParserBuilder.parsewordlist","page":"API documentation","title":"CitableParserBuilder.parsewordlist","text":"Parse a list of tokens with a CitableParser.\n\nparsewordlist(vocablist, p; data)\n\n\nReturns a Dict mapping strings to a (possibly empty) vector of Analysis objects.\n\n\n\n\n\n","category":"function"},{"location":"man/#CitableParserBuilder.parselistfromfile","page":"API documentation","title":"CitableParserBuilder.parselistfromfile","text":"Parse a list of tokens in a file with a CitableParser.\n\nparselistfromfile(f, p)\nparselistfromfile(f, p, delim; data)\n\n\n\n\n\n\n","category":"function"},{"location":"man/#CitableParserBuilder.parselistfromurl","page":"API documentation","title":"CitableParserBuilder.parselistfromurl","text":"Parse a list of tokens at a given url with a CitableParser.\n\n\n\n\n\n","category":"function"},{"location":"man/#CitableParserBuilder.parsepassage","page":"API documentation","title":"CitableParserBuilder.parsepassage","text":"Parse a CitablePassage with text for a single token with a CitableParser.\n\nparsepassage(cn, p; data)\n\n\nShould return an AnalyzedToken.\n\n\n\n\n\n","category":"function"},{"location":"man/#CitableParserBuilder.parsecorpus","page":"API documentation","title":"CitableParserBuilder.parsecorpus","text":"Use a CitableParser to parse a CitableTextCorpus with each citable node containing containg a single token.\n\nparsecorpus(c, p; data)\n\n\nShould return a list of AnalyzedTokens.\n\n\n\n\n\n","category":"function"},{"location":"man/#Profiling-parsed-results","page":"API documentation","title":"Profiling parsed results","text":"","category":"section"},{"location":"man/","page":"API documentation","title":"API documentation","text":"vocabulary_density\ntoken_coverage\nvocabulary_coverage\nlexical_density\nform_density_incorpus\nform_density_invocabulary\nform_density_inlexicon\nformal_ambiguity\nlexical_ambiguity","category":"page"},{"location":"man/#CitableParserBuilder.vocabulary_density","page":"API documentation","title":"CitableParserBuilder.vocabulary_density","text":"Ratio of distinct tokens to size of corpus.\n\nvocabulary_density(tp)\n\n\n\n\n\n\nCompute ratio of distinct tokens to size of corpus.\n\nvocabulary_density(tc)\n\n\n\n\n\n\n","category":"function"},{"location":"man/#CitableParserBuilder.token_coverage","page":"API documentation","title":"CitableParserBuilder.token_coverage","text":"Percentage of all tokens parsed.\n\ntoken_coverage(tp)\n\n\n\n\n\n\nCompute percentage of all tokens parsed.\n\ntoken_coverage(tc)\n\n\n\n\n\n\n","category":"function"},{"location":"man/#CitableParserBuilder.vocabulary_coverage","page":"API documentation","title":"CitableParserBuilder.vocabulary_coverage","text":"Percentage of unique tokens parsed.\n\nvocabulary_coverage(tp)\n\n\n\n\n\n\nCompute percentage unique tokens parsed.\n\nvocabulary_coverage(tc)\n\n\n\n\n\n\n","category":"function"},{"location":"man/#CitableParserBuilder.lexical_density","page":"API documentation","title":"CitableParserBuilder.lexical_density","text":"Ratio of lexicon size to number of tokens parsed.\n\nlexical_density(tp)\n\n\n\n\n\n\nCompute ratio of lexicon size to number of tokens parsed.\n\nlexical_density(tc)\n\n\n\n\n\n\n","category":"function"},{"location":"man/#CitableParserBuilder.form_density_incorpus","page":"API documentation","title":"CitableParserBuilder.form_density_incorpus","text":"Ratio of tokens to distinct forms.\n\nform_density_incorpus(tp)\n\n\n\n\n\n\nCompute ratio of tokens to distinct forms.\n\nform_density_incorpus(tc)\n\n\n\n\n\n\n","category":"function"},{"location":"man/#CitableParserBuilder.form_density_invocabulary","page":"API documentation","title":"CitableParserBuilder.form_density_invocabulary","text":"Ratio of vocabulary items to distinct forms.\n\nform_density_invocabulary(tp)\n\n\n\n\n\n\nCompute ratio of vocabulary items to distinct forms.\n\nform_density_invocabulary(tc)\n\n\n\n\n\n\n","category":"function"},{"location":"man/#CitableParserBuilder.form_density_inlexicon","page":"API documentation","title":"CitableParserBuilder.form_density_inlexicon","text":"Ratio of lexicon to distinct forms.\n\nform_density_inlexicon(tp)\n\n\n\n\n\n\nCompute ratio of lexicon to distinct forms.\n\nform_density_inlexicon(tc)\n\n\n\n\n\n\n","category":"function"},{"location":"man/#CitableParserBuilder.formal_ambiguity","page":"API documentation","title":"CitableParserBuilder.formal_ambiguity","text":"Ratio of distinct forms to all tokens parsed.\n\nformal_ambiguity(tp)\n\n\n\n\n\n\nCompute ratio of distinct forms to all tokens parsed.\n\nformal_ambiguity(tc)\n\n\n\n\n\n\nCompute morphological ambiguity in corpus analyzed by parser.\n\nformal_ambiguity(c, p; data)\n\n\n\n\n\n\nCompute morphological ambiguity in list of words analyzed by parser.\n\nformal_ambiguity(vocablist, p; data)\n\n\n\n\n\n\n","category":"function"},{"location":"man/#CitableParserBuilder.lexical_ambiguity","page":"API documentation","title":"CitableParserBuilder.lexical_ambiguity","text":"Ratio of lexically ambiguous tokens  to all parsed tokens.\n\nlexical_ambiguity(tp)\n\n\n\n\n\n\nCompute ratio of lexically ambiguous tokens  to all parsed tokens.\n\nlexical_ambiguity(tc)\n\n\n\n\n\n\nCompute lexical ambiguity in corpus analyzed by parser.\n\nlexical_ambiguity(c, p; data)\n\n\n\n\n\n\nCompute lexical ambiguity in list of words analyzed by parser.\n\nlexical_ambiguity(vocablist, p; data)\n\n\n\n\n\n\n","category":"function"},{"location":"man/#Working-with-vectors-of-AnalyzedTokens","page":"API documentation","title":"Working with vectors of AnalyzedTokens","text":"","category":"section"},{"location":"man/","page":"API documentation","title":"API documentation","text":"lexemes\nstringsforlexeme\nlexemedictionary","category":"page"},{"location":"man/#CitableParserBuilder.lexemes","page":"API documentation","title":"CitableParserBuilder.lexemes","text":"Extract a list of lexeme values from a Vector of AnalyzedTokens.\n\nlexemes(v)\n\n\n\n\n\n\n","category":"function"},{"location":"man/#CitableParserBuilder.stringsforlexeme","page":"API documentation","title":"CitableParserBuilder.stringsforlexeme","text":"Find token string values for all tokens in a vector of AnalyzedTokens parsed to a given lexeme.\n\nstringsforlexeme(v, l)\n\n\n\n\n\n\n","category":"function"},{"location":"man/#CitableParserBuilder.lexemedictionary","page":"API documentation","title":"CitableParserBuilder.lexemedictionary","text":"From a vector AnalyzedTokens and an index of tokens in a corpus, construct a dictionary keyed by lexemes, mapping to a further dictionary of surface forms to passages.\n\nlexemedictionary(parses, tokenindex)\n\n\n\n\n\n\n","category":"function"},{"location":"man/#Working-with-AbbreviatedUrns","page":"API documentation","title":"Working with AbbreviatedUrns","text":"","category":"section"},{"location":"man/","page":"API documentation","title":"API documentation","text":"abbreviate\nexpand\nfstsafe","category":"page"},{"location":"man/#CitableParserBuilder.abbreviate","page":"API documentation","title":"CitableParserBuilder.abbreviate","text":"Constructs an AbbreviatedUrn string from a Cite2Urn.\n\nabbreviate(urn)\n\n\nExample:\n\njulia> abbreviate(Cite2Urn(\"urn:cite2:kanones:lsj.v1:n123\"))\n\"lsj.n123\"\n\nExample: a pipeline abbreviating a Cite2Urn and forming a LexemeUrn from the abbreviated string value.\n\njulia> Cite2Urn(\"urn:cite2:kanones:lsj.v1:n123\") |> abbreviate |> LexemeUrn\nLexemeUrn(\"lsj\", \"n123\")\n\n\n\n\n\n","category":"function"},{"location":"man/#CitableParserBuilder.expand","page":"API documentation","title":"CitableParserBuilder.expand","text":"Constructs a Cite2Urn from an AbbreviatedUrn and a dictionary mapping collection identifiers in  AbbreviatedUrns's to full Cite2Urns for a versioned collection.\n\n\n\n\n\n","category":"function"},{"location":"man/#CitableParserBuilder.fstsafe","page":"API documentation","title":"CitableParserBuilder.fstsafe","text":"Compose SFST representation of an AbbreviatedUrn.\n\nfstsafe(au)\n\n\nExample:\n\njulia> LexemeUrn(\"lexicon.lex123\") |> fstsafe\n\"<u>lexicon\\.lex123</u>\"\n\n\n\n\n\n","category":"function"},{"location":"man/#Working-with-Stems-and-Rules","page":"API documentation","title":"Working with Stems and Rules","text":"","category":"section"},{"location":"man/","page":"API documentation","title":"API documentation","text":"CitableParserBuilder.lexeme\nCitableParserBuilder.id\nCitableParserBuilder.inflectiontype","category":"page"},{"location":"man/#CitableParserBuilder.lexeme","page":"API documentation","title":"CitableParserBuilder.lexeme","text":"Function required to get lexeme  value of a Stem implementation.\n\n\n\n\n\n","category":"function"},{"location":"man/#CitableParserBuilder.id","page":"API documentation","title":"CitableParserBuilder.id","text":"Function required to get ID value of a Stem implementation.\n\n\n\n\n\nFunction required to get ID value of a Rule implementation.\n\n\n\n\n\n","category":"function"},{"location":"man/#CitableParserBuilder.inflectiontype","page":"API documentation","title":"CitableParserBuilder.inflectiontype","text":"Function required to get string value for inflection class of a Stem implementation.\n\n\n\n\n\nFunction required to get string value for inflection class of a Rule implementation.\n\n\n\n\n\n","category":"function"},{"location":"man/#Serialization","page":"API documentation","title":"Serialization","text":"","category":"section"},{"location":"man/","page":"API documentation","title":"API documentation","text":"readfst\nanalyses_relationsblock\ndelimited\ncex","category":"page"},{"location":"man/#CitableParserBuilder.readfst","page":"API documentation","title":"CitableParserBuilder.readfst","text":"Read SFST output from file f, and parse into a dictionary keying tokens to a (possibly empty) array of SFST strings.\n\nreadfst(f)\n\n\n\n\n\n\n","category":"function"},{"location":"man/#CitableParserBuilder.analyses_relationsblock","page":"API documentation","title":"CitableParserBuilder.analyses_relationsblock","text":"Compose a CEX relationset block for a set of analyses.\n\nanalyses_relationsblock(urn, label, v)\nanalyses_relationsblock(urn, label, v, delim; registry)\n\n\n\n\n\n\n","category":"function"},{"location":"man/#CitableParserBuilder.delimited","page":"API documentation","title":"CitableParserBuilder.delimited","text":"Serialize an Analysis to delimited text. Abbreviated URNs are expanded to full CITE2 URNs using registry as the expansion dictionary.\n\ndelimited(a)\ndelimited(a, delim; registry)\n\n\n\n\n\n\nSerialize a Vector of Analysis objects as delimited text.\n\ndelimited(v)\ndelimited(v, delim; registry)\n\n\n\n\n\n\nSerialize a single AnalyzedToken as one or more lines of delimited text.\n\ndelimited(at)\ndelimited(at, delim; registry)\n\n\n\n\n\n\nSerialize a Vector of AnalyzedTokens as delimited text.\n\ndelimited(v)\ndelimited(v, delim; registry)\n\n\n\n\n\n\n","category":"function"},{"location":"man/#CitableBase.cex","page":"API documentation","title":"CitableBase.cex","text":"Delegate to specific functions based on  type's citable trait value.\n\ncex(x)\ncex(x, delim)\n\n\n\n\n\n\nIt is an error to invoke the cex function on material that is not citable.\n\ncex(_, x, delim)\n\n\n\n\n\n\nCitable text content should implement cex.\n\ncex(_, txt, delim)\n\n\n\n\n\n\nCitable content should implement cex.\n\ncex(_, obj, delim)\n\n\n\n\n\n\nFormat a CitablePassage as a delimited-text string.\n\ncex(psg)\ncex(psg, delim)\n\n\nRequired function for Citable abstraction.\n\n\n\n\n\nFormat a CitableDocument as a CEX ctsdata block.\n\ncex(doc)\ncex(doc, delim)\n\n\n\n\n\n\nCompose a delimited-text string for a corpus.\n\ncex(c)\ncex(c, delimiter)\n\n\n\n\n\n\nImplement cex function required by Citable interface  for CatalogedText.\n\ncex(cataloged)\ncex(cataloged, delimiter)\n\n\n\n\n\n\nSerialize an AnalyzedToken as delimited text (required for Citable interface).\n\ncex(at)\ncex(at, delim)\n\n\nUses abbreviated URNs.   These can be expanded to full CITE2 URNs when read back with a URN registry, or the delimited function can be used with a URN registry to write full CITE2 URNs.\n\n\n\n\n\n","category":"function"},{"location":"guide/parsers/#Examples-of-CitableParsers","page":"Examples of CitableParsers","title":"Examples of CitableParsers","text":"","category":"section"},{"location":"guide/parsers/","page":"Examples of CitableParsers","title":"Examples of CitableParsers","text":"The following Julia modules implement the CitableParser abstraction:","category":"page"},{"location":"guide/parsers/","page":"Examples of CitableParsers","title":"Examples of CitableParsers","text":"Kanones: ancient Greek. Github.\nTabulae: Latin. Docs. Github.\nLycian: Lycian. Docs.Github.","category":"page"},{"location":"guide/abbrurns/#Abbreviated-URN-values","page":"Abbreviated URN values","title":"Abbreviated URN values","text":"","category":"section"},{"location":"guide/abbrurns/","page":"Abbreviated URN values","title":"Abbreviated URN values","text":"The AbbreviatedUrn is an abstract type supporting an abbreviated notation for Cite2Urns. It allows you to work with objects uniquely identified by collection identifier and object identifier, when the collection is registered in a dictionary that can expand the collection identifier to a full Cite2Urn.","category":"page"},{"location":"guide/abbrurns/","page":"Abbreviated URN values","title":"Abbreviated URN values","text":"The modules implements the AbbrevatedUrn for each uniquely identified component of an Analysis:","category":"page"},{"location":"guide/abbrurns/","page":"Abbreviated URN values","title":"Abbreviated URN values","text":"LexemeUrn\nFormUrn\nStemUrn\nRuleUrn","category":"page"},{"location":"guide/abbrurns/","page":"Abbreviated URN values","title":"Abbreviated URN values","text":"An AbbreviatedUrn has a collection identifier, and an object identifier.  You can construct an AbbreviatedUrn from a dot-delimited string.","category":"page"},{"location":"guide/abbrurns/","page":"Abbreviated URN values","title":"Abbreviated URN values","text":"using CitableParserBuilder\nlexurn = LexemeUrn(\"lsj.n125\")\nlexurn.collection\n\n# output\n\n\"lsj\"","category":"page"},{"location":"guide/abbrurns/","page":"Abbreviated URN values","title":"Abbreviated URN values","text":"lexurn.objectid\n\n# output\n\n\"n125\"","category":"page"},{"location":"guide/abbrurns/#Abbreviated-URNs-and-Cite2Urns","page":"Abbreviated URN values","title":"Abbreviated URNs and Cite2Urns","text":"","category":"section"},{"location":"guide/abbrurns/","page":"Abbreviated URN values","title":"Abbreviated URN values","text":"You can use the abbreviate function to create an abbreviation string from a Cite2Urn using the collection identifier and the object identifer of the Cite2Urn.","category":"page"},{"location":"guide/abbrurns/","page":"Abbreviated URN values","title":"Abbreviated URN values","text":"using CitableParserBuilder, CitableObject\nconjunctionurn = Cite2Urn(\"urn:cite2:kanones:morphforms.v1:1000000001\")\nabbreviate(conjunctionurn)\n\n# output\n\n\"morphforms.1000000001\"","category":"page"},{"location":"guide/abbrurns/","page":"Abbreviated URN values","title":"Abbreviated URN values","text":"Of course you can use this string in turn to instantiate an AbbreviatedUrn structure.","category":"page"},{"location":"guide/abbrurns/","page":"Abbreviated URN values","title":"Abbreviated URN values","text":"formurn = abbreviate(conjunctionurn) |> FormUrn\ntypeof(formurn)\n\n# output\n\nFormUrn","category":"page"},{"location":"guide/abbrurns/","page":"Abbreviated URN values","title":"Abbreviated URN values","text":"formurn.objectid\n\n# output\n\n\"1000000001\"","category":"page"},{"location":"guide/abbrurns/","page":"Abbreviated URN values","title":"Abbreviated URN values","text":"To convert an AbbreviatedUrn to a full Cite2Urn, give the expand function a dictionary mapping collection identifiers to full URN strings for the collection","category":"page"},{"location":"guide/abbrurns/","page":"Abbreviated URN values","title":"Abbreviated URN values","text":"registry = Dict(\n    \"morphforms\" => \"urn:cite2:kanones:morphforms.v1:\"\n)\nexpanded = expand(formurn, registry)\ntypeof(expanded)\n\n# output\n\nCite2Urn","category":"page"},{"location":"guide/abbrurns/","page":"Abbreviated URN values","title":"Abbreviated URN values","text":"expanded.urn\n\n# output\n\n\"urn:cite2:kanones:morphforms.v1:1000000001\"","category":"page"},{"location":"guide/abbrurns/#Abbreviated-URNs-and-SFST-PL","page":"Abbreviated URN values","title":"Abbreviated URNs and SFST-PL","text":"","category":"section"},{"location":"guide/abbrurns/","page":"Abbreviated URN values","title":"Abbreviated URN values","text":"The fstsafe function composes an expression in SFST-PL for AbbrevatiedUrns.  It assumes that your SFST alphabet includes tokens <u> and </u> to mark beginning and ending boundaries of URN values. It escapes characters that are valid in URNs but reserved in the Stuttgart FST toolkit.  ","category":"page"},{"location":"guide/abbrurns/","page":"Abbreviated URN values","title":"Abbreviated URN values","text":"rule = RuleUrn(\"nouninfl.h_hs1\")\nfst = fstsafe(rule)\n\n# output\n\n\"<u>nouninfl\\\\.h\\\\_hs1</u>\"","category":"page"},{"location":"guide/abbrurns/","page":"Abbreviated URN values","title":"Abbreviated URN values","text":"","category":"page"},{"location":"guide/analyses/#User's-guide:-working-with-analyses","page":"User's guide: working with analyses","title":"User's guide: working with analyses","text":"","category":"section"},{"location":"guide/analyses/","page":"User's guide: working with analyses","title":"User's guide: working with analyses","text":"The Analysis type represents the results of analyzing a string morphologically.","category":"page"},{"location":"guide/analyses/","page":"User's guide: working with analyses","title":"User's guide: working with analyses","text":"The AnalyzedToken type associates a Vector of Analysis objects with a citable token.  The AnalyzedToken should cite the text at the level of the individual token, normally by expanding the citation hierarchy on level to identify tokens within a canonically citable unit.  The Vector of analyses associated with an AnalyzedToken may be empty. This means that no analyis was found for the given token.  ","category":"page"},{"location":"guide/analyses/","page":"User's guide: working with analyses","title":"User's guide: working with analyses","text":"The string value for the token in an AnalyzedToken  represents the string as it appears in the cited text.  The string for the token in an Analysis represents the string that was analyzed.  These two values may or may not be identical.  If the token was normalized in some way before analysis (e.g., adjusting case or accent) they may differ.","category":"page"},{"location":"guide/analyses/","page":"User's guide: working with analyses","title":"User's guide: working with analyses","text":"The following page illustrates functions analyzing an entire corpus.","category":"page"},{"location":"guide/buildone/#Worked-example:-build-your-own-CitableParser","page":"Worked example: build your own CitableParser","title":"Worked example: build your own CitableParser","text":"","category":"section"},{"location":"guide/buildone/#.-Define-your-parser-type","page":"Worked example: build your own CitableParser","title":"1. Define your parser type","text":"","category":"section"},{"location":"guide/buildone/","page":"Worked example: build your own CitableParser","title":"Worked example: build your own CitableParser","text":"Import CitableParserBuilder, and define your parser as a subtype of CitableParser.","category":"page"},{"location":"guide/buildone/","page":"Worked example: build your own CitableParser","title":"Worked example: build your own CitableParser","text":"using CitableParserBuilder\nstruct FakeParser <: CitableParser\n    label\nend\nfakeParser = FakeParser(\"Parser generating dummy values\")\n\n# output\n\nFakeParser(\"Parser generating dummy values\")","category":"page"},{"location":"guide/buildone/#.-Implement-parsetoken","page":"Worked example: build your own CitableParser","title":"2. Implement parsetoken","text":"","category":"section"},{"location":"guide/buildone/","page":"Worked example: build your own CitableParser","title":"Worked example: build your own CitableParser","text":"Be sure to import CitableParserBuilder: parsetoken before defining a method of parsetoken for your parser's type.  You're done!  You can now use parsetoken and all the other functions of the ParserTrait.","category":"page"},{"location":"guide/buildone/","page":"Worked example: build your own CitableParser","title":"Worked example: build your own CitableParser","text":"import CitableParserBuilder: parsetoken\nfunction parsetoken(s::AbstractString, parser::FakeParser; data = nothing) \n    # Returns only the same analysis no matter\n    # what the token is\n    [\n        Analysis(\n        s,\n        LexemeUrn(\"fakeparser.nolexemeanalysis\"),\n        FormUrn(\"fakeparser.noformanalysis\"),\n        StemUrn(\"fakeparser.nostemanalysis\"),\n        RuleUrn(\"fakeparser.noruleanalysis\")\n    )\n    ]\nend\ntokenparses = parsetoken(\"word\", fakeParser)\ntokenparses[1].token\n\n# output\n\n\"word\"","category":"page"},{"location":"guide/buildone/","page":"Worked example: build your own CitableParser","title":"Worked example: build your own CitableParser","text":"wordlist = split(\"More than one word\")\nlistparses = parsewordlist(wordlist, fakeParser)\nlength(listparses)\n\n# output\n\n4","category":"page"},{"location":"guide/gburg/#Appendix:-a-note-on-the-citable-parser","page":"Appendix: a note on the citable parser","title":"Appendix: a note on the citable parser","text":"","category":"section"},{"location":"guide/gburg/","page":"Appendix: a note on the citable parser","title":"Appendix: a note on the citable parser","text":"The GettysburgParser used in this demonstration works with a simple dictionary of tokens to POS tags.  The dictionary was constructed by wrapping the Python NLTK POS tagger with a Julia function. This page documents how to do that so that you can generically apply the NTLK tagger to a list of tokens from Julia.","category":"page"},{"location":"guide/gburg/#Python-prerequisites","page":"Appendix: a note on the citable parser","title":"Python prerequisites","text":"","category":"section"},{"location":"guide/gburg/","page":"Appendix: a note on the citable parser","title":"Appendix: a note on the citable parser","text":"You need to have Python, with nltk.","category":"page"},{"location":"guide/gburg/","page":"Appendix: a note on the citable parser","title":"Appendix: a note on the citable parser","text":"pip install nltk","category":"page"},{"location":"guide/gburg/","page":"Appendix: a note on the citable parser","title":"Appendix: a note on the citable parser","text":"Then start python, and at the python prompt,","category":"page"},{"location":"guide/gburg/","page":"Appendix: a note on the citable parser","title":"Appendix: a note on the citable parser","text":"import nltk\nnltk.download","category":"page"},{"location":"guide/gburg/#A-Julia-wrapper","page":"Appendix: a note on the citable parser","title":"A Julia wrapper","text":"","category":"section"},{"location":"guide/gburg/","page":"Appendix: a note on the citable parser","title":"Appendix: a note on the citable parser","text":"# If you're in a system with python accessible\n# and the nltk module installed, you can actually\n# execute all the code blocks on this page.\nrepo = pwd() |> dirname  |> dirname |> dirname\ngburgfile = repo * \"/test/data/gettysburg/gettysburgcorpus.cex\"\nusing CitableCorpus\ncorpus = corpus_fromfile(gburgfile, \"|\")","category":"page"},{"location":"guide/gburg/","page":"Appendix: a note on the citable parser","title":"Appendix: a note on the citable parser","text":"note: Note\nIn the extra directory, the script engpos.jl does everything documented here, and can be run from the command line from the root of the repository with julia --project=extra/ extra/engpos.jl","category":"page"},{"location":"guide/gburg/","page":"Appendix: a note on the citable parser","title":"Appendix: a note on the citable parser","text":"In Julia, you can make the NLTK module's tag function available like this:","category":"page"},{"location":"guide/gburg/","page":"Appendix: a note on the citable parser","title":"Appendix: a note on the citable parser","text":"using Conda\nConda.add(\"nltk\")\nusing PyCall\n@pyimport nltk.tag as ptag","category":"page"},{"location":"guide/gburg/","page":"Appendix: a note on the citable parser","title":"Appendix: a note on the citable parser","text":"Now if we have a citable corpus named corpus, we can use the TextAnalysis functions to extract a unique lexicon, and apply the NLTK tagger to it.","category":"page"},{"location":"guide/gburg/","page":"Appendix: a note on the citable parser","title":"Appendix: a note on the citable parser","text":"using CitableCorpusAnalysis\nusing TextAnalysis\ntacorp = tacorpus(corpus)\n\ntkns = []\nfor doc in tacorp.documents\n    push!(tkns, tokens(doc))\nend\ntknlist = tkns |> Iterators.flatten |> collect |> unique\ntagged = ptag.pos_tag(tknlist)","category":"page"},{"location":"guide/corpusanalysis/#Analyzing-and-profiling-a-corpus","page":"Analyzing and profiling a corpus","title":"Analyzing and profiling a corpus","text":"","category":"section"},{"location":"guide/corpusanalysis/#Analyzing-a-corpus","page":"Analyzing and profiling a corpus","title":"Analyzing a corpus","text":"","category":"section"},{"location":"guide/corpusanalysis/","page":"Analyzing and profiling a corpus","title":"Analyzing and profiling a corpus","text":"The CitableParserBuilder defines a number of functions that draw on a concrete implementation of the parsetoken function to analyze a citable corpus.","category":"page"},{"location":"guide/corpusanalysis/","page":"Analyzing and profiling a corpus","title":"Analyzing and profiling a corpus","text":"We'll load a citable corpus from a file in this repository's test/data directory (referred to here as f).","category":"page"},{"location":"guide/corpusanalysis/","page":"Analyzing and profiling a corpus","title":"Analyzing and profiling a corpus","text":"using CitableCorpus\nrepo = dirname(pwd()) |> dirname |> dirname # hide\ncorpuscexfile = joinpath(repo,\"test\",\"data\",\"gettysburgcorpus.cex\") \ncorpus = read(corpuscexfile) |> corpus_fromcex","category":"page"},{"location":"guide/corpusanalysis/","page":"Analyzing and profiling a corpus","title":"Analyzing and profiling a corpus","text":"We'll use the SimpleAscii orthography from the Orthography package to prepare a tokenized corpus.","category":"page"},{"location":"guide/corpusanalysis/","page":"Analyzing and profiling a corpus","title":"Analyzing and profiling a corpus","text":"using Orthography\ntc = tokenizedcorpus(corpus, simpleAscii())","category":"page"},{"location":"guide/corpusanalysis/","page":"Analyzing and profiling a corpus","title":"Analyzing and profiling a corpus","text":"We'll build a GettysburgParser, a demo parser for the English text of the Gettysburg Address in two steps.  First we'll load a local file with analytical data into a dictionary (here named morphdict). Then we'll include that as an optional dict parameter when we build the parser.","category":"page"},{"location":"guide/corpusanalysis/","page":"Analyzing and profiling a corpus","title":"Analyzing and profiling a corpus","text":"The result of parsing the corpus is a Vector of AnalyzedTokens.  There is one entry for each token in the corpus.","category":"page"},{"location":"guide/corpusanalysis/","page":"Analyzing and profiling a corpus","title":"Analyzing and profiling a corpus","text":"dictcsv = joinpath(repo, \"test\", \"data\", \"posdict.csv\") \nusing CSV\nmorphdict = CSV.File(dictcsv) |> Dict\nusing CitableParserBuilder\nparser = CitableParserBuilder.gettysburgParser(dict = morphdict)\nparsed =  parsecorpus(tc, parser; data = parser.data)\nlength(parsed)","category":"page"},{"location":"guide/corpusanalysis/","page":"Analyzing and profiling a corpus","title":"Analyzing and profiling a corpus","text":"The vector of analyses can be formatted as delimited text with the delimited function.  If you include an optional registry mapping collection names to full CITE2 collection strings, abbreviated URNs will be expanded in the resulting text.","category":"page"},{"location":"guide/corpusanalysis/","page":"Analyzing and profiling a corpus","title":"Analyzing and profiling a corpus","text":"urndict = Dict(\n    \"gburglex\" => \"urn:cite2:citedemo:gburglex.v1:\",\n    \"gburgform\" => \"urn:cite2:citedemo:gburgform.v1:\",\n    \"gburgrule\" => \"urn:cite2:citedemo:gburgrule.v1:\",\n    \"gburgstem\" => \"urn:cite2:citedemo:gburgstem.v1:\"\n)\ndelimited_output = tempname()\nopen(delimited_output, \"w\") do io\n    write(io, delimited(parsed; registry = urndict))\nend","category":"page"},{"location":"guide/corpusanalysis/","page":"Analyzing and profiling a corpus","title":"Analyzing and profiling a corpus","text":"We can read the file with analyzedtokens_fromcex to create a new Vector of analyses.","category":"page"},{"location":"guide/corpusanalysis/","page":"Analyzing and profiling a corpus","title":"Analyzing and profiling a corpus","text":"analyzedTokens = read(delimited_output, String) |> analyzedtokens_fromcex","category":"page"},{"location":"guide/corpusanalysis/","page":"Analyzing and profiling a corpus","title":"Analyzing and profiling a corpus","text":"(We'll be tidy and remove the temporary file.) ","category":"page"},{"location":"guide/corpusanalysis/","page":"Analyzing and profiling a corpus","title":"Analyzing and profiling a corpus","text":"rm(delimited_output)","category":"page"},{"location":"guide/corpusanalysis/#Profiling-a-corpus","page":"Analyzing and profiling a corpus","title":"Profiling a corpus","text":"","category":"section"},{"location":"guide/corpusanalysis/","page":"Analyzing and profiling a corpus","title":"Analyzing and profiling a corpus","text":"We can get a summary profile of the corpus in a couple of different ways.  At the cost of reparsing the corpus, we can simply use the profile function","category":"page"},{"location":"guide/corpusanalysis/","page":"Analyzing and profiling a corpus","title":"Analyzing and profiling a corpus","text":"profile1 = profile(tc, parser; data = parser.data)","category":"page"},{"location":"guide/corpusanalysis/","page":"Analyzing and profiling a corpus","title":"Analyzing and profiling a corpus","text":"Alternatively, we can reuse our existing Vector of AnalyticalTokens like this.","category":"page"},{"location":"guide/corpusanalysis/","page":"Analyzing and profiling a corpus","title":"Analyzing and profiling a corpus","text":"counts = count_analyses(parsed)\nlabel = \"Profile for \" * string(tc)\nprofile2 = profile(counts, label)","category":"page"},{"location":"guide/corpusanalysis/","page":"Analyzing and profiling a corpus","title":"Analyzing and profiling a corpus","text":"The profile object has a ton of useful information.","category":"page"},{"location":"guide/corpusanalysis/","page":"Analyzing and profiling a corpus","title":"Analyzing and profiling a corpus","text":" vocabulary_density(profile1)","category":"page"},{"location":"guide/corpusanalysis/","page":"Analyzing and profiling a corpus","title":"Analyzing and profiling a corpus","text":" token_coverage(profile1)","category":"page"},{"location":"guide/corpusanalysis/","page":"Analyzing and profiling a corpus","title":"Analyzing and profiling a corpus","text":"See the API documentation for a full list of the functions you can apply to a profile.","category":"page"},{"location":"#CitableParserBuilder:-overview","page":"Overview","title":"CitableParserBuilder:  overview","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"The CitableParserBuilder module offers common functions and data structures for working with citable morphological analyses of citable texts.  ","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"At the center of the module are the abstract CitableParser, and the concrete Analysis and AnalyzedToken types. ","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Parsing functions use a CitableParser to operate either on string values for individual tokens, or on passages of text citable with CTS URNs at the token level.  This harmonizes nicely with the Orthography module's functions for tokenizing strings and citable text structures.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Parsing a string value returns a (possibly empty) list of Analysis objects.  Parsing a citable passage returns an AnalyzedToken, which pairs the citable passage with the analyses resulting from parsing the passage's text content.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"tip: Tip\nYou can use an OrthographicSystem to create a complete tokenized edition from a citable edition. See the documentation for the Orthography module.","category":"page"},{"location":"#Shared-functions-for-parsing:-the-CitableParser-abstraction","page":"Overview","title":"Shared functions for parsing: the CitableParser abstraction","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"Types implementing the CitableParser abstraction must have a member function named stringparser(tkn::AbstractString) that returns a list of Analysis objects.  That makes possible a parsetoken function with the following signature:","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"parsetoken(p::T, t::AbstractString) where {T <: CitableParser}","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"parsetoken simply invokes p.stringparser(t) to parse the string value for a single token.  With this in place, the CitableParserBuilder can include concrete implementations of the following functions:","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"parsetoken: parse a string value\nparsewordlist: parse a list of string values\nparselistfromfile: parse a list of string values in a local file\nparselistfromurl: parse a list of string values from the contents of a URL\nparsepassage: parse the text component of a CitablePassage as a single token\nparsecorpus: parse the text components of all nodes in a CitableCorpus as individual tokens","category":"page"},{"location":"#Shared-structures:-the-Analysis-and-the-AnalyzedToken","page":"Overview","title":"Shared structures: the Analysis and the AnalyzedToken","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"Every analysis of a string value identifies a valid pairing of a lexeme and a form for the token.  The Analysis further supports a typical model of computational morphological analysis that crosses a lexicon of stems with a set of inflectional patterns to create a comprehensive set of recognized forms. The stem and rule of an Analysis explain how the analysis' lexeme and form were arrived at.  The structure of the Analysis therefore consists of four URN values:","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"the lexeme\nthe morphological form\nthe stem used to arrive at the analysis\nthe inflectional rule used to arrive at the analysis","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"The AnalyzedToken type associates a Vector of Analysis objects with a citable token.","category":"page"},{"location":"#Shared-functions-for-working-with-results-of-parsing","page":"Overview","title":"Shared functions for working with results of parsing","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"lexemes \nstringsforlexeme \nlexemedictionary","category":"page"},{"location":"#Examples","page":"Overview","title":"Examples","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"The following sections illustrate parsing with a sample implementation of a CitableParser designed to parse a corpus of all the known versions of Lincoln's Gettysburg Address, and to identify the form of tokens with the part of speech code used by the Penn treebank project.","category":"page"},{"location":"#Contents","page":"Overview","title":"Contents","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"Pages = [\n    \"guide/parser.md\",\n    \"guide/analyses.md\",\n    \"guide/corpusanalysis.md\",\n    \"guide/parsevectors.md\",\n    \"guide/abbrurns.md\",\n    \"guide/utils.md\",\n    \"guide/parsers.md\",\n    \"guide/gburg.md\",\n    \"man/index.md\"\n]","category":"page"}]
}
